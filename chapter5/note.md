* 线程网络，一个线程网络是由若干线程块组成的。每个线程块都是二维的。每次最多能够开启$Y\times X \times T$个线程。

* CUDA的内核只是一个在GPU上运行的函数。在调用内核的时候必须按照以下的语法来进行：
  $$
  kernel   \_  function<<<num\_blocks,num\_threads>>>(param1, param2,\dots)
  $$
  num_threads表示的是执行内核函数的线程数目。在一般的循环中线程的数目可以为循环迭代的次数。

  内核调用的下一部分是参数的传递，我们可以通过寄存器以及常量内存来进行参数的传递。一般来说每个线程需要一个寄存器来传递一个参数。



GPU每个至少需要支持的内存是256MB。线程块的线程数量最好是一个线程束大小的整数倍。一般系统以整个线程束为一个基本的单位进行调度。为了让C语言中的数组也能够很好地进行映射，线程块也可以看做是一个二维的结构。也就是有宽度跨度和偏移。一般来说数组的宽度值最好是线程束大小的整数倍。

二维线程索引可以用二维的方式访问数组。主要有blockDim.x与blockDim.y

我们最好要用行的方式来进行连续的内存访问。同一个线程块可以通过共享内存进行通信。在正方形的布局中，需要两次的访问。

dim3是CUDA中的一个特殊的数据结构。主要是能够创建一个二维的线程块和线程网格。

#### 线程束

线程束是GPU的基本执行单元。每个线程束中的线程同时进行。当使用GPU进行编程的时候，必须使用向量类型指令。

**分支**

GPU处理分支和CPU不同。GPU在执行完分支结构的一个分支之后会执行另外的一个分支。对不满足分支条件的线程，GPU在执行完这块代码的时候会将其设置为未激活的状态。当这块代码执行完毕之后，GPU继续执行另外的一个分支。这时候如果刚刚不满足分支条件的线程如果满足当前的分支条件，那么被激活并且执行。

GPU的利用率，在这里CUDA是通过许多的线程来隐藏内存操作的延迟。每个线程块上面如果线程数目越多，那么就是增加了等待执行较慢的线程束的可能性。

线程块的调度：

所有线程块的执行顺序都是不确定的。所有说在GPU上，可能就会有其他的一些顺序带来的影响。比如用浮点数的操作，每次相加的顺序不一样，最后的结果也是不一样的。线程块的数目最好都是SM的整数倍。

硬件的竞争能力也会带来很大的影响。包括半线程束合并读取内存数据。

共享内存是一块较为特殊的内存，他存在与芯片之上并且他的存取速度比全局的内存更快。我们可以利用其来加快速度。