#### CUDA内存处理

存储带宽：一定时间内从DRAM读出或者写入的数据量。延迟：响应一个获取内存的请求所花费的时间。

高速缓存的最大速度与缓存的大小成反比。缓存在处理器的核或者SM之间进行共享。

**数据储存类型**

GPU提供了不同层次的若干区域来存放数据，每块区域根据其能够达到的最大带宽以及延迟而定义。比如有独立的一级缓存和共享的二级缓存。最快速的依次为寄存器，共享内存，常量内存，纹理内存，常规设备内存，最后是主机端内存。我们要思考如何高效地访问全局内存，也要想办法减少对全局内存的访问次数。

#### 寄存器的用法

GPU的每个SM有上千个寄存器。CPU和GPU架构的一个主要区别就是他们中的映射寄存器的方式。CPU在运行新的任务的时候需要进行上下文切换。而GPU利用多线程来隐藏一些内存获取与指令执行带来的延迟。所以在GPU上进行上下文切换的时候，所需要的操作就是将指向当前寄存器的指针进行更新。

GPU能够在硬件上调度的线程块分配固定数目的寄存器组。每个SM使用的寄存器的空间大小也不同。**指令级的并行**是可以用流水线的技术来实现的。

如何使用寄存器来进行优化牵涉到编译器。

使用全局内存的内核函数中，线程块中的每个线程都在进行读写。但是没有保证按照怎么样的顺序运行。因此输出是不确定的。使用寄存器能够带来很大的优化效果。

#### 共享内存

共享内存是用户可以控制的一级缓存。当数据重复利用，全局内存合并，或者线程之间有共享数据时使用共享内存才更加合适。共享内存是基于存储体切换的架构。所以我们必须要解决存储体冲突的问题。线程访问共享内存的时候需要排队等候。

**共享内存排序**

在GPU上线程块的大小或者线程束的大小可以理想地映射为数据集的大小。对于一个长为N的数据，我们可以最多用N/2个线程来进行。

以行的方式访问全局内存的时候，性能最好。

#### 并行归约

他可以使用数据集元素数量一半的线程，每个线程将当前线程对于的元素与另外一个元素进行比较，计算两者之间的最小值，这样就可以将最小值移到最前面。每进行一次比较，线程数目就减少一半，这样可以直到只剩下一个元素为止。

#### 常量内存

常量内存是全局内存的一种虚拟地址形式。并没有特殊保留的常量内存块。它有两个特点，一个是高速缓存，另一个是它支持将单个值广播到线程束中的每个线程。

常量内存的大小被限制为64K.在编译的时候，为了声明一块常量内存，我们需要用到关键字__ constant __

常量内存的广播机制：

广播能够在一个周期内完成。常量内存区能够达到和一级缓存相同的速度。

#### 全局内存

CPU的主机端处理器能够通过以下三种方式对GPU上的内存进行访问：

* 显式地阻塞传输
* 显式地非阻塞传输
* 隐式地使用零内存复制

CPU聚集->传输到GPU->GPU内核处理->传输回CPU->CPU处理

合并大小支持32字节，64字节以及128字节，分别表示线程束中每个线程以一个字节，16位，32位为单位读取数据。

如何获取对齐的内存块：

```
extern __host__ cudaError_t CUDARTAPI cudaMallocPitch(void **devPtr, size_t* pitch, size_t width, size_t height);
```

第一个参数是指向设备内存指针的指针，第二个参数表示指向对齐之后每行真实字节数的指针，第三个参数是需要开辟的数组的宽度，第四个是高度。

一般在这里需要注意的是如何进行对齐。有时候需要使用这个函数进行自动的填充。

**记分牌**

全局内存可以使用记分牌。在GPU中，表达式中只有用到变量a的时候才会真正到内存中取值。可以是一种惰性计算模型。我们可以简单地将内存获取操作放到内核的开始处，然后再在内核中进行调用。

#### 纹理内存

每个SM上的6~8KB的纹理内存为此设备提供了唯一真正缓存数据的方式。纹理缓存是通常用来做局部优化的机制。纹理内存的第二个也是最有用的一个特性就是当访问储存单元的时候，其允许GPU某些硬件方面的自动实现。

主要是希望可以支持双线性与三线性插值。